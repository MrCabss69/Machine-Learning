{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Cómo podemos tomar la mejor decisión con información incompleta?\n",
    "\n",
    "Esta es justamente la pregunta que trata de resolver la teoría de juegos de información incompleta. Tomar la mejor decisión en juego que implica un conflicto de intereses, involucra no ser predecibles, ya que de lo contrario nos convertiríamos en explotables. Otro agente del entrono podría preever nuestras acciones de antemano y modificar su estrategia en conscuencia para maximizar su beneficio; más si el juego es de suma 0 que aparte de maximizar su beneficio, intentará minimizar el nuestro.\n",
    "\n",
    "\n",
    "Un algoritmo simple que propone el cálculo de estrategias óptimas en juegos de suma cero, es el regret matching. Mediante simulaciones, pretende actualizar las estrategias de los agentes, con el objetivo de converger a un equilibrio de Nash. La lógica es la siguiente: ir midiendo lo que habríamos ganado de haber elegido una acción distinta en el pasado, si todo se hubiera mantenido igual. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo Trabajado: Khun Poker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kuhn Poker Setup\n",
    "cards_values = { \"J\": 1, \"Q\": 2, \"K\": 3 }\n",
    "HANDS        = [ 'JQ', 'JK', 'QJ', 'KJ', 'QK', 'KQ' ]\n",
    "ACTIONS      = { 0: 'pass', 1: 'bet' }\n",
    "STATES       = [ c + ' ' + s for c in cards_values.keys() for s in ['', '0', '1','01'] ]\n",
    "TERMINALS    = [ h + ' ' + s for h in HANDS for s in ['11','00','010', '10', '011'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones del juego\n",
    "def deal():\n",
    "    \"\"\"Selecciona una mano aleatoria de las posibles manos.\"\"\"\n",
    "    return random.choice(HANDS)\n",
    "\n",
    "def payments(hands, h):\n",
    "    \"\"\"Calcula el pago basado en las manos y el historial de acciones.\"\"\"\n",
    "    if h not in TERMINALS:\n",
    "        return 0\n",
    "    payment = 2 if h.count('1') < 2 else 4\n",
    "    return -payment if (h[-2:] == '01' or (cards_values[hands[1]] > cards_values[hands[0]] and h[-2] == h[-1])) else payment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialización de arrepentimientos y política\n",
    "regrets      = {state: np.zeros(len(ACTIONS)) for state in STATES}\n",
    "strategies   = {state: np.zeros(len(ACTIONS)) for state in STATES}\n",
    "\n",
    "def get_strategy(state):\n",
    "    \"\"\"Calcula la estrategia para un estado dado basado en los arrepentimientos acumulados.\"\"\"\n",
    "    state_regrets = regrets[state]\n",
    "    s = sum([ 0 if state_regrets[i] <=0 else state_regrets[i] for i in range(len(state_regrets))])\n",
    "    if s  > 0:\n",
    "        strategy = [ r/s if r > 0 else 0 for r in state_regrets] \n",
    "    else:\n",
    "        strategy = np.ones(len(ACTIONS)) / len(ACTIONS)\n",
    "    strategies[state] += strategy  # Acumula la estrategia\n",
    "    return strategy\n",
    "\n",
    "def get_action(strategy):\n",
    "    \"\"\"Elige una acción basada en la distribución de probabilidad de la estrategia.\"\"\"\n",
    "    return np.random.choice(list(ACTIONS.keys()), p=strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento con el algoritmo\n",
    "iters = 100_000\n",
    "for t in range(iters):\n",
    "    cards   = deal()\n",
    "    history = cards + ' '\n",
    "    actions_ = []\n",
    "\n",
    "    for player in range(2):\n",
    "        \n",
    "        if history in TERMINALS:\n",
    "            break\n",
    "\n",
    "        state    = cards[player] + ' ' + history[3:]\n",
    "        strategy = get_strategy(state)\n",
    "        action   = get_action(strategy)\n",
    "        actions_.append(action)\n",
    "        history += str(action)\n",
    "\n",
    "    # Ejecutar acción pendiente si no es terminal\n",
    "    if not history in TERMINALS:\n",
    "        state    = cards[0] + ' ' + history[3:]\n",
    "        strategy = get_strategy(state)\n",
    "        action   = get_action(strategy)\n",
    "        actions_.append(action)\n",
    "        history += str(action)\n",
    "\n",
    "    payment = payments(cards, history)\n",
    "\n",
    "    # Actualización de arrepentimientos\n",
    "    for i in range(len(actions_)):\n",
    "        idx = i % 2\n",
    "        state = cards[idx] + ' ' + ''.join(map(str, actions_[:i]))\n",
    "        for a in ACTIONS.keys():\n",
    "            hypothetical_history = cards + ' ' + ''.join(map(str, actions_[:i] + [a] + actions_[i+1:]))\n",
    "            # recodificación del historial en caso especial\n",
    "            hypothetical_history = hypothetical_history.replace('110', '11')                                    \n",
    "            hypothetical_payment = payments(cards, hypothetical_history)\n",
    "            regret = hypothetical_payment - payment if idx == 0 else -hypothetical_payment + payment\n",
    "            regrets[state][a] += regret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'J ': array([16858.86942927, 16362.13057073]),\n",
       " 'J 0': array([10476.33339138,  7414.66660862]),\n",
       " 'J 1': array([1.56555e+04, 1.50000e+00]),\n",
       " 'J 01': array([170.,   1.]),\n",
       " 'Q ': array([18892.39636803, 14462.60363197]),\n",
       " 'Q 0': array([16397.3559273,   337.6440727]),\n",
       " 'Q 1': array([6.14285714e+00, 1.65218571e+04]),\n",
       " 'Q 01': array([   4., 3901.]),\n",
       " 'K ': array([16712., 16712.]),\n",
       " 'K 0': array([1.7677e+04, 1.0000e+00]),\n",
       " 'K 1': array([5.00000e-01, 1.55105e+04]),\n",
       " 'K 01': array([2.000e+00, 3.625e+03])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'J ': [0.5074762779346557, 0.49252372206534417],\n",
       " 'J 0': [0.5855644397395475, 0.41443556026045253],\n",
       " 'J 1': [0.9999041962061698, 9.580379383023568e-05],\n",
       " 'J 01': [0.9941520467836257, 0.005847953216374269],\n",
       " 'Q ': [0.5664037286173996, 0.4335962713826004],\n",
       " 'Q 0': [0.9798240769227249, 0.020175923077275157],\n",
       " 'Q 1': [0.00037166367030839434, 0.9996283363296915],\n",
       " 'Q 01': [0.001024327784891165, 0.9989756722151089],\n",
       " 'K ': [0.5, 0.5],\n",
       " 'K 0': [0.9999434325149904, 5.656748500961647e-05],\n",
       " 'K 1': [3.223518793114564e-05, 0.9999677648120688],\n",
       " 'K 01': [0.0005514199062586159, 0.9994485800937414]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def avg_strategy(strategy_sum):\n",
    "    \"\"\"Calcula la estrategia promedio a partir de la suma de estrategias.\"\"\"\n",
    "    total = sum(strategy_sum)\n",
    "    return [s / total for s in strategy_sum] if total > 0 else [1 / len(strategy_sum) for _ in strategy_sum]\n",
    "\n",
    "average_strategies = {k: avg_strategy(v) for k, v in strategies.items()}\n",
    "average_strategies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
